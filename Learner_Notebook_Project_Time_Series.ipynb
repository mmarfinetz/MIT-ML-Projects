{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Project:-Time-Series---Forecasting-Stock-Prices\"><strong>Project: Time Series - Forecasting Stock Prices</strong><a class=\"anchor-link\" href=\"#Project:-Time-Series---Forecasting-Stock-Prices\">¶</a></h1><h1 id=\"Marks:-30\">Marks: 30<a class=\"anchor-link\" href=\"#Marks:-30\">¶</a></h1><p>Welcome to the project on Time Series. We will use the Amazon Stock Prices dataset for this project.</p>\n",
    "<hr/>\n",
    "<h2 id=\"Context:\"><strong>Context:</strong><a class=\"anchor-link\" href=\"#Context:\">¶</a></h2><hr/>\n",
    "<p><strong>Stocks are one of the most popular financial instruments invented for building wealth</strong> and are the <strong>centerpiece of any investment portfolio.</strong> Recent advances in trading technology have opened up stock markets in such a way that nowadays, <strong>nearly anybody can own stock.</strong></p>\n",
    "<p>In the last few decades, there's been an <strong>explosive increase in the average person's interest for the stock market.</strong> This makes stock value prediction an interesting and popular problem to explore.</p>\n",
    "<hr/>\n",
    "<h2 id=\"Objective:\"><strong>Objective:</strong><a class=\"anchor-link\" href=\"#Objective:\">¶</a></h2><hr/>\n",
    "<p>Amazon.com, Inc. engages in the retail sale of consumer products and subscriptions in North America as well as internationally. This dataset consists of monthly average stock closing prices of Amazon over a period of 12 years from 2006 to 2017. We have to <strong>build a time series model</strong> using the AR, MA, ARMA and ARIMA models in order to <strong>forecast the stock closing price of Amazon.</strong></p>\n",
    "<hr/>\n",
    "<h2 id=\"Data-Dictionary:\"><strong>Data Dictionary:</strong><a class=\"anchor-link\" href=\"#Data-Dictionary:\">¶</a></h2><hr/>\n",
    "<ul>\n",
    "<li><strong>date:</strong> Date when the price was collected</li>\n",
    "<li><strong>close:</strong> Closing price of the stock</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Importing-libraries\">Importing libraries<a class=\"anchor-link\" href=\"#Importing-libraries\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Please note that we are downgrading the version of the statsmodels library to version 0.12.1.</strong> Due to some variation, the latest version of the library might not give us the desired results. You can run the below code to downgrade the library and avoid any issues in the output. Once the code runs successfully, either restart the kernel or restart the Jupyter Notebook before importing the statsmodels library.It is enough to run the install statsmodel cell once.To be sure you are using the correct version of the library, you can use the code in the Version check cell of the model.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels==0.12.1\n",
      "  Using cached statsmodels-0.12.1.tar.gz (17.4 MB)\n",
      "  Installing build dependencies ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[53 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.6\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.7\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Collecting setuptools\n",
      "  \u001b[31m   \u001b[0m   Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting wheel\n",
      "  \u001b[31m   \u001b[0m   Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting cython>=0.29.14\n",
      "  \u001b[31m   \u001b[0m   Using cached cython-3.1.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting numpy==1.17.5\n",
      "  \u001b[31m   \u001b[0m   Using cached numpy-1.17.5.zip (6.4 MB)\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: started\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "  \u001b[31m   \u001b[0m   \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m╰─>\u001b[0m \u001b[31m[22 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Running from numpy source directory.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m <string>:419: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/Users/mitch/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/Users/mitch/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/Users/mitch/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 175, in prepare_metadata_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     return hook(metadata_directory, config_settings)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/v2/dbndjj356rzcs68w9pczqcpm0000gn/T/pip-build-env-qlc3660b/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 374, in prepare_metadata_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/v2/dbndjj356rzcs68w9pczqcpm0000gn/T/pip-build-env-qlc3660b/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 512, in run_setup\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     super().run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/v2/dbndjj356rzcs68w9pczqcpm0000gn/T/pip-build-env-qlc3660b/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 317, in run_setup\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"<string>\", line 444, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"<string>\", line 423, in setup_package\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/v2/dbndjj356rzcs68w9pczqcpm0000gn/T/pip-install-xm7cipr4/numpy_74ae632ae8d74252af9a983d1b908646/numpy/distutils/__init__.py\", line 6, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     from . import ccompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   File \"/private/var/folders/v2/dbndjj356rzcs68w9pczqcpm0000gn/T/pip-install-xm7cipr4/numpy_74ae632ae8d74252af9a983d1b908646/numpy/distutils/ccompiler.py\", line 111, in <module>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     replace_method(CCompiler, 'find_executables', CCompiler_find_executables)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m NameError: name 'CCompiler' is not defined. Did you mean: 'ccompiler'?\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m \u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "  \u001b[31m   \u001b[0m \u001b[1;36mhint\u001b[0m: See above for details.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels==0.12.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Version check \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mstatsmodels\u001b[39;00m\n\u001b[32m      3\u001b[39m statsmodels.__version__\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "# Version check \n",
    "import statsmodels\n",
    "statsmodels.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing libraries for visualization\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Importing library for date manipulation\n",
    "from datetime import datetime\n",
    "\n",
    "#To calculate the MSE or RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Importing acf and pacf functions\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "#Importing models from statsmodels library\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "#To ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Reading-the-dataset\">Reading the dataset<a class=\"anchor-link\" href=\"#Reading-the-dataset\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you are having an issue while loading the excel file in pandas, please run the below command in anaconda prompt, otherwise ignore.\n",
    "#conda install -c anaconda xlrd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('amazon_stocks_prices.xlsx')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Checking-info\">Checking info<a class=\"anchor-link\" href=\"#Checking-info\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Question-1:-Check-the-info-of-the-dataset-and-write-your-observations.-(2-Marks)\"><strong>Question 1: Check the info of the dataset and write your observations. (2 Marks)</strong><a class=\"anchor-link\" href=\"#Question-1:-Check-the-info-of-the-dataset-and-write-your-observations.-(2-Marks)\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "df.info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:The data is 144 rows by 2 columns. As the rows increase in time, the closing price tends to increase over time.</strong></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting date as the index\n",
    "df = df.set_index(['date'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Now, let's <strong>visualize the time series</strong> to get an idea about the trend and/or seasonality within the data.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the time series\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Closing Prices\")\n",
    "plt.title('Amazon Stock Prices')\n",
    "plt.plot(df.index, df.close, color = 'c', marker='.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:</strong></p>\n",
    "<ul>\n",
    "<li>We can see that the series has an <strong>upward trend with some seasonality.</strong> This implies that the <strong>average stock price of Amazon has been increasing almost every year.</strong></li>\n",
    "<li>Before building different models, it is important to <strong>check whether the series is stationary or not.</strong></li>\n",
    "</ul>\n",
    "<p>Let us first split the dataset into train and test data</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Splitting-the-dataset\">Splitting the dataset<a class=\"anchor-link\" href=\"#Splitting-the-dataset\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "df_train = df.loc['2006-01-01':'2015-12-01']\n",
    "df_test = df.loc['2016-01-01' : '2017-12-01']\n",
    "print(df_train)\n",
    "print(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Now let us check the <strong>rolling mean and standard deviation</strong> of the series to <strong>visualize if the series has any trend or seasonality.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Testing-the-stationarity-of-the-series\">Testing the stationarity of the series<a class=\"anchor-link\" href=\"#Testing-the-stationarity-of-the-series\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the rolling mean and standard deviation for a window of 12 observations\n",
    "rolmean=df_train.rolling(window=12).mean()\n",
    "rolstd=df_train.rolling(window=12).std()\n",
    "\n",
    "#Visualizing the rolling mean and standard deviation\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "actual = plt.plot(df_train, color='c', label='Actual Series')\n",
    "rollingmean = plt.plot(rolmean, color='red', label='Rolling Mean') \n",
    "#rollingstd = plt.plot(rolstd, color='green', label='Rolling Std. Dev.')\n",
    "plt.title('Rolling Mean & Standard Deviation of the Series')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:</strong></p>\n",
    "<ul>\n",
    "<li>We can see there is an upward trend in the series.</li>\n",
    "<li>We can confirm that <strong>the series is not stationary.</strong></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We can also use the <strong>Augmented Dickey-Fuller (ADF) Test</strong> to verify if the series is stationary or not.\n",
    "The null and alternate hypotheses for the ADF Test are defined as:</p>\n",
    "<ul>\n",
    "<li><strong>Null hypothesis:</strong> The Time Series is non-stationary</li>\n",
    "<li><strong>Alternative hypothesis:</strong> The Time Series is stationary</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to use adfuller test\n",
    "def adfuller(df_train):\n",
    "  #Importing adfuller using statsmodels\n",
    "  from statsmodels.tsa.stattools import adfuller\n",
    "  print('Dickey-Fuller Test: ')\n",
    "  adftest = adfuller(df_train['close'])\n",
    "  adfoutput = pd.Series(adftest[0:4], index=['Test Statistic','p-value','Lags Used','No. of Observations'])\n",
    "  for key,value in adftest[4].items():\n",
    "    adfoutput['Critical Value (%s)'%key] = value\n",
    "  print(adfoutput)\n",
    "adfuller(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:</strong></p>\n",
    "<ol>\n",
    "<li>From the above test, we can see that the <strong>p-value = 1 i.e. &gt; 0.05</strong> (For 95% confidence intervals) therefore, <strong>we fail to reject the null hypothesis.</strong></li>\n",
    "<li>Hence, <strong>we can confirm that the series is non-stationary.</strong></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Making-the-series-stationary\">Making the series stationary<a class=\"anchor-link\" href=\"#Making-the-series-stationary\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We can use some of the following methods to convert a non-stationary series into a stationary one:</p>\n",
    "<ol>\n",
    "<li><strong>Log Transformation</strong></li>\n",
    "<li><strong>By differencing the series (lagged series)</strong></li>\n",
    "</ol>\n",
    "<p>Let's first use a log transformation over this series to remove exponential variance and check the stationarity of the series again.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the rolling mean and standard deviation after using log transformation\n",
    "plt.figure(figsize=(16,8))\n",
    "df_log = np.log(df_train)\n",
    "MAvg = df_log.rolling(window=12).mean()\n",
    "MStd = df_log.rolling(window=12).std()\n",
    "plt.plot(df_log)\n",
    "plt.plot(MAvg, color='r', label = 'Moving Average')\n",
    "plt.plot(MStd, color='g', label = 'Standard Deviation')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:</strong></p>\n",
    "<ul>\n",
    "<li>Since <strong>we can still see the upward trend in the series</strong>, we can conclude that <strong>the series is still non-stationary.</strong> </li>\n",
    "<li>However, the standard deviation is almost constant which implies that <strong>now the series has constant variance.</strong></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Let's shift the series by order 1 (or by 1 month) &amp; apply differencing (using lagged series)</strong> and then check the rolling mean and standard deviation.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Question-2:-Visualize-the-rolling-mean-and-rolling-standard-deviation-of-the-shifted-series-(df_shift)-and-check-the-stationarity-by-calling-the-adfuller()-function.-Also,-write-your-observations-on-the-same.-(3-Marks)\"><strong>Question 2: Visualize the rolling mean and rolling standard deviation of the shifted series (df_shift) and check the stationarity by calling the adfuller() function. Also, write your observations on the same. (3 Marks)</strong><a class=\"anchor-link\" href=\"#Question-2:-Visualize-the-rolling-mean-and-rolling-standard-deviation-of-the-shifted-series-(df_shift)-and-check-the-stationarity-by-calling-the-adfuller()-function.-Also,-write-your-observations-on-the-same.-(3-Marks)\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "df_shift = df_log - df_log.shift(periods = 1)\n",
    "MAvg = df_log.rolling(window=12).mean()\n",
    "MStd = df_log.rolling(window=12).std()\n",
    "plt.plot(df_shift, color='c')\n",
    "plt.plot(MAvg, color='red', label = 'Moving Average')\n",
    "plt.plot(MStd, color='green', label = 'Standard Deviation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Dropping the null values that we get after applying differencing method\n",
    "df_shift = df_shift.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:The mean and standard deviation tend to stay constant overtime, while the moving average has a positve slope.</strong></p>\n",
    "<p>Let us use the adfuller test to check the stationarity.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(df_shift) # call the adfuller function for df_shift series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:</strong></p>\n",
    "<ul>\n",
    "<li><strong>The P-value is now signigicantly less than 0.05. Therfore we can reject the null hypothesis and conclude this time series is now stationary.</strong></li>\n",
    "</ul>\n",
    "<p>Let's decompose the time series to check its different components.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Decomposing-the-time-series-components-into-Trend,-Seasonality-and-Residual\">Decomposing the time series components into Trend, Seasonality and Residual<a class=\"anchor-link\" href=\"#Decomposing-the-time-series-components-into-Trend,-Seasonality-and-Residual\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the seasonal_decompose function to decompose the time series\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomp = seasonal_decompose(df_train)\n",
    "\n",
    "trend = decomp.trend\n",
    "seasonal = decomp.seasonal\n",
    "residual = decomp.resid\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(411)\n",
    "plt.plot(df_train, label='Actual', marker='.')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend', marker='.')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal, label='Seasonality', marker='.')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals', marker='.')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:</strong></p>\n",
    "<ul>\n",
    "<li>We can see that there are significant <strong>trend, seasonality and residuals components</strong> in the series</li>\n",
    "<li>The plot for seasonality shows that <strong>Amazon's stock prices spike in July, September, and December.</strong></li>\n",
    "</ul>\n",
    "<p><strong>Now let's move on to the model building section. First, we will plot the <code>ACF</code> and <code>PACF</code> plots to get the values of p and q i.e. order of AR and MA models to be used.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Plotting-the-auto-correlation-function-and-partial-auto-correlation-function-to-get-p-and-q-values-for-AR,-MA,-ARMA,-and-ARIMA-models\">Plotting the auto-correlation function and partial auto-correlation function to get p and q values for AR, MA, ARMA, and ARIMA models<a class=\"anchor-link\" href=\"#Plotting-the-auto-correlation-function-and-partial-auto-correlation-function-to-get-p-and-q-values-for-AR,-MA,-ARMA,-and-ARIMA-models\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "\n",
    "plt.figure(figsize = (16,8))\n",
    "plot_acf(df_shift, lags = 12) \n",
    "plt.show() \n",
    "plot_pacf(df_shift, lags = 12) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:</strong></p>\n",
    "<ul>\n",
    "<li>From the above PACF plot we can see that <strong>the highest lag</strong> at which the plot extends beyond the statistically significant boundary is <strong>lag 1.</strong> </li>\n",
    "<li>This indicates that an <strong>AR Model of lag 1 (p=1)</strong> should be sufficient to fit the data.</li>\n",
    "<li>Similarly, from the ACF plot, we can infer that <strong>q=1.</strong></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"AR-Model\">AR Model<a class=\"anchor-link\" href=\"#AR-Model\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Question-3:-Fit-and-predict-the-shifted-series-with-the-AR-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(5-Marks)\"><strong>Question 3: Fit and predict the shifted series with the AR Model and calculate the RMSE. Also, visualize the time series and write your observations. (5 Marks)</strong><a class=\"anchor-link\" href=\"#Question-3:-Fit-and-predict-the-shifted-series-with-the-AR-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(5-Marks)\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing AutoReg function to apply AR model\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "model_AR = AutoReg(df_shift, lags = 1) #Use number of lags as 1 and apply AutoReg function on df_shift series\n",
    "results_AR = model_AR.fit() #fit the model\n",
    "plt.plot(df_shift)\n",
    "predict = results_AR.predict(start = 0, end = len(df_shift)-1) #predict the series \n",
    "predict = predict.fillna(0) #Converting NaN values to 0\n",
    "plt.plot(predict, color='red')\n",
    "plt.title('AR Model - RMSE: %.4f'% mean_squared_error(predict,df_shift['close'], squared=False))  #Calculating rmse\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:The Root Mean Squarred Error for this model is 0.09.</strong></p>\n",
    "<p><strong>Let's check the AIC value</strong> of the model</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_AR.aic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Now, let's build MA, ARMA, and ARIMA models as well, and see if we can get a better model</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"MA-Model\">MA Model<a class=\"anchor-link\" href=\"#MA-Model\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>We will be using an ARIMA model with p=0 and d=0 so that it will work as an MA model</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Question-4:-Fit-and-predict-the-shifted-series-with-the-MA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\"><strong>Question 4: Fit and predict the shifted series with the MA Model and calculate the RMSE. Also, visualize the time series and write your observations. (2 Marks)</strong><a class=\"anchor-link\" href=\"#Question-4:-Fit-and-predict-the-shifted-series-with-the-MA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "plt.figure(figsize=(16,8))\n",
    "model_MA = ARIMA(df_shift['close'], order=(0, 0, 1))\n",
    "results_MA = model_MA.fit()\n",
    "plt.plot(df_shift)\n",
    "plt.plot(results_MA.fittedvalues.index, results_MA.fittedvalues, color='red')\n",
    "plt.title('MA Model - RMSE: %.4f' % mean_squared_error(results_MA.fittedvalues, df_shift['close'].loc[results_MA.fittedvalues.index], squared=False))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:The MA Model gives almost an identical RMSE score of 0.902, only 0.002 greater than the score of the AR model.</strong></p>\n",
    "<p>Let's check the AIC value of the model</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_MA.aic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li><strong>The MA model is giving a much lower AIC</strong> when compared to the AR model, implying that <strong>the MA model fits the training data better.</strong> </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"ARMA-Model\">ARMA Model<a class=\"anchor-link\" href=\"#ARMA-Model\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We will be using an <strong>ARIMA model with p=1 and q=1</strong> (as observed from the ACF and PACF plots) <strong>and d=0 so that it will work as an ARMA model.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Question-5:-Fit-and-predict-the-shifted-series-with-the-ARMA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\"><strong>Question 5: Fit and predict the shifted series with the ARMA Model and calculate the RMSE. Also, visualize the time series and write your observations. (2 Marks)</strong><a class=\"anchor-link\" href=\"#Question-5:-Fit-and-predict-the-shifted-series-with-the-ARMA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "model_ARMA = ARIMA(df_shift['close'], order=(1, 0, 1))\n",
    "results_ARMA = model_ARMA.fit()\n",
    "plt.plot(df_shift)\n",
    "plt.plot(results_ARMA.fittedvalues.index, results_ARMA.fittedvalues, color='red')\n",
    "plt.title('ARMA Model - RMSE: %.4f' % mean_squared_error(results_ARMA.fittedvalues, df_shift['close'].loc[results_ARMA.fittedvalues.index], squared=False))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:</strong></p>\n",
    "<ul>\n",
    "<li><strong>This ARMA model keeps the same RMSE score as the previous MA model of 0.0902.</strong></li>\n",
    "</ul>\n",
    "<p><strong>Let's check the AIC value</strong> of the model</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ARMA.aic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li><strong>The AIC value of the ARMA model is more or less similar</strong> to MA model </li>\n",
    "</ul>\n",
    "<p><strong>Let us try using the ARIMA Model.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"ARIMA-Model\">ARIMA Model<a class=\"anchor-link\" href=\"#ARIMA-Model\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We will be using an <strong>ARIMA Model with p=1, d=1, &amp; q=1</strong>.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Question-6:-Fit-and-predict-the-shifted-series-with-the-ARIMA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\"><strong>Question 6: Fit and predict the shifted series with the ARIMA Model and calculate the RMSE. Also, visualize the time series and write your observations. (2 Marks)</strong><a class=\"anchor-link\" href=\"#Question-6:-Fit-and-predict-the-shifted-series-with-the-ARIMA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "model_ARIMA =  ARIMA(df_log['close'], order=(1,1,1))\n",
    "results_ARIMA = model_ARIMA.fit()\n",
    "plt.plot(df_shift)\n",
    "plt.plot(results_ARIMA.fittedvalues.index, results_ARIMA.fittedvalues, color='red')\n",
    "common_idx = results_ARIMA.fittedvalues.index.intersection(df_shift.index)\n",
    "rmse = mean_squared_error(results_ARIMA.fittedvalues.loc[common_idx], df_shift['close'].loc[common_idx], squared=False)\n",
    "plt.title('ARIMA Model - RMSE: %.4f' % rmse)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:Again the model has the same RMSE score as the MA model and ARMA model.</strong></p>\n",
    "<p><strong>Let's check the AIC value</strong> of the model</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ARIMA.aic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li><strong>The AIC value of the ARIMA model is the same</strong> as the ARMA model. </li>\n",
    "</ul>\n",
    "<p>We can see that <strong>all the models return almost the same RMSE.</strong> There is not much difference in AIC value as well across all the models except for the AR model.</p>\n",
    "<p><strong>We can choose to predict the values using ARIMA as it takes into account more factors than AR, MA, ARMA models.</strong></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the fitted values\n",
    "predictions=pd.Series(results_ARIMA.fittedvalues)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Inverse-Transformation\">Inverse Transformation<a class=\"anchor-link\" href=\"#Inverse-Transformation\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Now we have fitted values using the ARIMA model, <strong>we will use the inverse transformation to get back the original values.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Question-7:-Apply-an-inverse-transformation-on-the-predictions-of-the-ARIMA-Model.-(5-Marks)\"><strong>Question 7: Apply an inverse transformation on the predictions of the ARIMA Model. (5 Marks)</strong><a class=\"anchor-link\" href=\"#Question-7:-Apply-an-inverse-transformation-on-the-predictions-of-the-ARIMA-Model.-(5-Marks)\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First step - doing cumulative sum\n",
    "predictions_cumsum = predictions.cumsum() # use .cumsum fuction on the predictions\n",
    "predictions_cumsum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second step - Adding the first value of the log series to the cumulative sum values\n",
    "predictions_log = pd.Series(df_log['close'].iloc[0], index=df_log.index)\n",
    "predictions_log = predictions_log.add(predictions_cumsum, fill_value=0)\n",
    "predictions_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third step - applying exponential transformation\n",
    "predictions_ARIMA = np.exp(predictions_log) #use exponential function\n",
    "predictions_ARIMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the original vs predicted series\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(df_train, color = 'c', label = 'Original Series')  #plot the original train series\n",
    "plt.plot(predictions_ARIMA, color = 'r', label = 'Predicted Series')  #plot the predictions_ARIMA \n",
    "plt.title('Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:</strong></p>\n",
    "<ul>\n",
    "<li>We can see that <strong>the predicted series is very similar to the original series</strong> i.e. The model is good at predicting values on the training data except for the dip in stock prices in 2015 which may have been due to some external factors that are not included in this model. </li>\n",
    "<li>Let us <strong>forecast the closing prices for the next 24 months.</strong></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Forecasting-the-values-for-next-24-months-and-compare-it-with-test-data\">Forecasting the values for next 24 months and compare it with test data<a class=\"anchor-link\" href=\"#Forecasting-the-values-for-next-24-months-and-compare-it-with-test-data\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>To forecast the values for the next 24 months using the ARIMA model, we need to follow the steps below:</strong></p>\n",
    "<ol>\n",
    "<li>Forecast the log-transformed fitted values for the next 24 months</li>\n",
    "<li>Make a list of these 24 month (2016-2017) forecasted values</li>\n",
    "<li>Convert that list into a series so that we can work with pandas functions </li>\n",
    "<li>Make a dataframe where we have the dates starting from 2016-01-01 to 2017-12-01 as the index and the respective forecasted values</li>\n",
    "<li>Apply the inverse transformation and get the real forecasted values</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Question-8:-Forecast-the-stocks-prices-for-the-next-24-months-and-perform-the-inverse-transformation.-(5-Marks)\"><strong>Question 8: Forecast the stocks prices for the next 24 months and perform the inverse transformation. (5 Marks)</strong><a class=\"anchor-link\" href=\"#Question-8:-Forecast-the-stocks-prices-for-the-next-24-months-and-perform-the-inverse-transformation.-(5-Marks)\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting the values for next 24 months\n",
    "forecasted_ARIMA = results_ARIMA.get_forecast(steps=24).predicted_mean\n",
    "forecasted_ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series containing all the forecasted values\n",
    "series1 = pd.Series(forecasted_ARIMA)\n",
    "series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a new dataframe to get the additional dates from 2016-2017 (24 months)\n",
    "index = pd.date_range('2016-01-01', periods=24, freq='MS')\n",
    "df1 = pd.DataFrame({'forecasted': series1.values}, index=index)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying exponential transformation to the forecasted log values\n",
    "forecasted_ARIMA = np.exp(df1['forecasted']) #use exponential function on forecasted data\n",
    "forecasted_ARIMA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Now, let's try to visualize the original data with the predicted values on the training data and the forecasted values.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the original vs predicted series\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(df, color = 'c', label = 'Original Series')\n",
    "plt.plot(predictions_ARIMA, color = 'r', label = 'Prediction on Train data') #plot the predictions_ARIMA series\n",
    "plt.plot(forecasted_ARIMA, label = 'Prediction on Test data', color='b')  #plot the forecasted_ARIMA series\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:</strong></p>\n",
    "<ul>\n",
    "<li><strong>As observed earlier, most of the predicted values on the training data are very close to the actual values</strong> except for the dip in stock prices in the year 2015.</li>\n",
    "<li><strong>On the test data, the model is able to correctly predict the trend of the stock prices</strong>, as we can see that the blue line appears to be close to the actual values (cyan blue) and they both have an upward trend. <strong>However the test predictions are not able to identify the volatile variations in the stock prices over the last 2 years.</strong></li>\n",
    "</ul>\n",
    "<p>Let's test the RMSE of the transformed predictions and the original value on the training and testing data to check whether the model is giving a generalized performance or not.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Question-9:-Check-the-RMSE-on-the-original-train-and-test-data-and-write-your-conclusion-from-the-above-analysis.-(4-Marks)\"><strong>Question 9: Check the RMSE on the original train and test data and write your conclusion from the above analysis. (4 Marks)</strong><a class=\"anchor-link\" href=\"#Question-9:-Check-the-RMSE-on-the-original-train-and-test-data-and-write-your-conclusion-from-the-above-analysis.-(4-Marks)\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "error = mean_squared_error(predictions_ARIMA, df_train, squared = False) #calculate RMSE using the predictions_ARIMA and df_train \n",
    "error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "error = mean_squared_error(forecasted_ARIMA, df_test, squared = False)  #calculate RMSE using the forecasted_ARIMA and df_test\n",
    "error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Conclusion\">Conclusion<a class=\"anchor-link\" href=\"#Conclusion\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Write your conclusion here</strong>\n",
    "The RMSE is lower on the training data compared to the testing data, indicating that predictions on the training data are closer to the actual values compared to the testing data. This is likely because the price is increasing at a greater rate in the twelve month period used for the testing data. As seen on the chart as time goes on, the price of the asset tends to increase exponentially. The model is also likely not complex enough to anticipate external factors that have a correlation on price.</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
